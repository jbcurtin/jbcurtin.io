<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title> Joe Curtin's Notebook(s) </title>
  <link href="https://jbcurtin.io/"/>
  <updated> 2021-03-24T14-17-45 </updated>
  <author>
    <name> Joe Curtin </name>
  </author>
  <id> https://jbcurtin.io/ </id>

  <entry>
    <title> How to use 'data-scripts' to setup a local Dask Scheduler and Dask Worker </title>
    <link href="https://jbcurtin.io/notebooks/data-scripts-and-Dask.html" />
    <id> https://jbcurtin.io/notebooks/data-scripts-and-Dask.html" </id>
    <updated> 2020-04-15T15-20-15 </updated>
    <summary> How to use 'data-scripts' to setup a local Dask Scheduler and Dask Worker

Depending on the science background you're coming from, there is a good chance you'll need to process a large amount of data. `data-scripts` aims to turn AWS S3, Digital Ocean Spaces, Google Cloud Storage, and Microsoft Blog storage into a massive Data Lake. All four major storage provides implement industry best stardards which allows us to store and pull data from across the world assuming we already have an index of the files being stored. `data-scripts` will focus on how to quickly insert data into your algorithms while keeping a mindful awareness of how much it might cost to do that </summary>
  </entry>

  <entry>
    <title> Importing JSON-Data into PostgreSQL </title>
    <link href="https://jbcurtin.io/notebooks/data-import-postgresql.html" />
    <id> https://jbcurtin.io/notebooks/data-import-postgresql.html" </id>
    <updated> 2020-06-14T18-26-41 </updated>
    <summary> Importing JSON-Data into PostgreSQL

Parsing JSON files can be quick and efficient, importing them into PostgreSQL may take some time. In this article, we'll examine how to save compute resource time by pre-processing the JSON format into a CSV format with PSQL datatypes to be imported into PostgreSQL. This method seems to be the quickest way to import data into PostgreSQL </summary>
  </entry>

  <entry>
    <title> Getting started with K8 </title>
    <link href="https://jbcurtin.io/notebooks/k8-getting-started.html" />
    <id> https://jbcurtin.io/notebooks/k8-getting-started.html" </id>
    <updated> 2020-11-27T04-14-29 </updated>
    <summary> Getting started with K8

After years of talking about it, I've started taking the time to really dig into a k8 environment. Having spent most of my career working with AWS. I've opt'd to learn more about GCP this time around. With it, I'm extending my vocabulary and looking into certifications. In the meantime, I'll make regular updates for moving from a Cloud Deployment strategy to Kubernetes. </summary>
  </entry>

  <entry>
    <title> CronJob management in kubenetes </title>
    <link href="https://jbcurtin.io/notebooks/k8-cronjob-management.html" />
    <id> https://jbcurtin.io/notebooks/k8-cronjob-management.html" </id>
    <updated> 2020-11-27T12-20-24 </updated>
    <summary> CronJob management in kubenetes

CronJobs were first released by Bell labs in 1975. Used to invoke periodic jobs on a given day, week, or month at a specific hour & specific minute. CronJob kind has made its way into the kubenetes API and are packed full of capabilities not immediately noticeable by one's imagination. Here is a workflow I developed that functions well and also provides a quick way to debug by creating Jobs from CronJobs. </summary>
  </entry>

</feed>